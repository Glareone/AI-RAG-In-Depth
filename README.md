OpenAI and ChatGPT repo

My Workshops and Posts
----------------
### My LinkedIn Posts & Presentations
1. [GenAI. Where could be applied. Post 1.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14013300/GenAI.Fields.Post.1.pdf)  
2. [GenAI in Application Refactoring field, Slides.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14013311/LinkedIn.post.day.2.compressed.pdf)  
3. [Legal problems with AI.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14013316/Legal.problems.with.AI.pdf)  
4. [Paradigms: Rag, Self-RAG, Re-Ranking RAG, FLARE v.2.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14037439/Rag.Self-RAG.FLARE.Re-Ranking.pdf)  
5. [Working with opinionated requests. S2A, RLHF, RLAIF.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14050997/Post.5.pdf)  
6. [Multi-Modal RAG and its features.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14077737/Post.6.pdf)   
7. [Measuring the GenAI Quality.pdf](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14156446/post.7.with.add.slides.pdf)
8. [LLM leveraging RLHF in code review](https://www.linkedin.com/posts/aleksei-kolesnikov-aa199217b_criticgpt-activity-7212381032992432128-OKvG)  
9. [Everything of Thoughts (XoT). All modern techniques in one place](https://www.linkedin.com/feed/update/urn:li:activity:7209092335526158336)  
10. [Non deterministic embedding results](https://www.linkedin.com/posts/aleksei-kolesnikov-aa199217b_ai-embeddings-openai-activity-7208369707937067009-gTkJ)
11. [AI Search vs PostgreSQL with pgvector in PROD](https://github.com/user-attachments/files/16404873/Post.10.-.AI.Search.vs.PostgreSQL.pdf)
12. [Prod-Ready LLM Solutions. Cook Book.](https://github.com/user-attachments/files/16471905/post.12.pdf)
13. [Quality Framework For RAG Applications.pdf](https://github.com/user-attachments/files/19273774/Quality.Framework.pdf)
14. Crew.AI. Agents in LLM Applications (In Progress)
15. Pydantic data classes and how to manage the output format (In Progress)
16. XML vs Markdown vs Json for tagging in prompting and metaprompting (In Progress)
17. Crawlers for LLMs:
    - https://python.langchain.com/v0.1/docs/use_cases/web_scraping/ ,
    - https://ai.gopubby.com/use-ai-to-scrape-almost-all-websites-easily-in-2025-f868adc41e0f,
    - https://github.com/Skyvern-AI/skyvern,
    - https://gotenberg.dev/docs/routes,
    - https://jina.ai/reader,
    - https://github.com/unclecode/crawl4ai,
    - https://crawlee.dev/,
    - https://github.com/bracesproul/site-rag/,
    - https://www.firecrawl.dev,
    - https://github.com/mishushakov/llm-scraper
19. Table extraction in RAG systems (In Progress)
20. [Choosing the right programming language for your next AI LLM project](https://github.com/user-attachments/files/18827122/Languages.for.AIpdf.pdf)
21. Misjudgements using LogProbs (In Progress)

### My Workshops
1. [June 2023. My Workshop Presentation. Run 1.pptx](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/11951964/Workshop.Introduction.pptx)  
2. [Online Workshop. ChatGPT -> Azure Function -> PowerAutomate. Run 2.pptx](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/13213425/Workshop.Introduction.v.3.pptx)
3. [Online Workshop. Run 3. Deep Learning -> Prompting -> ChatGPT -> Azure Function -> PowerAutomate](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/13368718/Workshop.Introduction.v.4.FINAL.pptx)
4. [Online+Offline Workshop for EHU University](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/13368730/EHU.Workshop.v.2.pptx)  
5. [Talk #3. RAG, FLARE, S2A, RLHF, RLAIF, Self-RAG, Re-Ranking. Common approaches and their pros & cons](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/14328529/GenAI.RAG.FLARE.Content.Filtering.pdf)  

Theoretical Part
----------------
0. [Six Principles of responsible AI](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/responsible-generative-ai.md)
1. [Responsible AI. Trusted AI Framework. Content Filters. Harmful Content. Prerelease Reviews](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/responsible-generative-ai.md)  
2. [What is ChatGPT Doing. and why does it work](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/?fbclid=IwAR0eV1C7bPYQeEX0BbmqR_8zAFTgf4S5q-bEXoG3ZK7fmxgMICj-QqW6ZWM)
3. [LLM UseCase in Google. Sorting Optimization](https://www.artisana.ai/articles/googles-deepmind-ai-shatters-records-with-a-70-faster-sorting-algorithm)
4. [Embeddings. Words to Vector. Useful in Search Scenarios and for Cognitive Search](https://platform.openai.com/docs/api-reference/embeddings/object)
5. [Cognitive Search. Video](https://www.youtube.com/watch?v=5z32NS4IG0w)
6. [Cognitive Search. From Zero to Hero](https://www.youtube.com/watch?v=shT9-7AofKU&t=1s)
7. [Cognitive Search. Indexers. AI Enrichment. Build-in Skills](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/azure-ai-search.md)  
8. [Transformers. Embeddings. Foundational Model](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Transformers-Embeddings-Foundational.md)
9. [Computer Vision. Cognitive. AI Face. Custom Vision](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Computer-Vision.md)
10. [Document Intelligence](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Document-intelligence.md)  
11. [Azure AI Speech. Speech To Text. Text To Speech. Azure Services](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/AI-Speech-To-Text-and-Text-To-Speech.md)
12. [Natural Language Processing(NLP). Text Meaning and analysis. General ways how to](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/natural-language-processing.md)
13. [Azure Language Service. Commands interpretation](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/language-understanding-commands-for-smart-home.md)  
14. [Azure Language Service. Question-Answer Knowledge base for bots. Question Answering service.](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/language-knowledge-base.md)
15. [Regression. Logistic and Linear Regression. Multiclass regression](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/regression-linear-and-logistic-regression.md)

### Azure AI-102 Learn Materials useful for exam
1. [AI Search. Debug Search Issues](https://learn.microsoft.com/en-us/training/modules/maintain-azure-cognitive-search-solution/07-debug-search-issues-use-azure-portal)
2. [AI Search. Performance and Monitoring](https://learn.microsoft.com/en-us/training/modules/maintain-azure-cognitive-search-solution/03-optimize-performance-of-azure-cognitive-search-solution)
3. [AI Search. Search and Scoring](https://learn.microsoft.com/en-us/training/modules/create-azure-cognitive-search-solution/7-enhance-index)
4. [AI Search. Implement Advanced Search Features. Scoring Profiles, Fuzzy Search, Term Boosting, Term Proximity](https://learn.microsoft.com/en-us/training/modules/implement-advanced-search-features-azure-cognitive-search/?sharingId=8A2C0E47AED1BEB)
5. [AI Search. Scoring profile lab. Add Different Language descriptions](https://microsoftlearning.github.io/mslearn-knowledge-mining/Instructions/Exercises/05-exercise-implement-enhancements-to-search-results.html)  
6. [AI Search. Enchance Index by translation using skills](https://learn.microsoft.com/en-us/training/modules/implement-advanced-search-features-azure-cognitive-search/05-enhance-index-to-include-multiple-languages)
7. [AI Search. Custom Skill using Azure Function](https://learn.microsoft.com/en-us/training/modules/create-azure-ai-custom-skill/1-introduction)  
8. [AI Search. Use Custom Analyzers (not default Microsoft Lucene)](https://learn.microsoft.com/en-us/training/modules/implement-advanced-search-features-azure-cognitive-search/04-improve-index-analyzers-tokenized-terms)
9. [AI Search. Geo-spatial functions](https://learn.microsoft.com/en-us/training/modules/implement-advanced-search-features-azure-cognitive-search/06-improve-search-experience-ordering-results-distance)
10. [AI Search. Knowledge Mining. Lab](https://microsoftlearning.github.io/mslearn-knowledge-mining/Instructions/Exercises/03-knowledge-store.html)
11. [AI Search -> PowerBI Table Projection from OCR Document Intelligence](https://learn.microsoft.com/en-us/azure/search/knowledge-store-projections-examples#define-a-table-projection)  
12. [Composed Document Intelligense Models. Case if you need to analyze several doc types](https://learn.microsoft.com/en-us/training/modules/create-composed-form-recognizer-model)
13. [Vision. Train a Custom Model using COCO](https://learn.microsoft.com/en-us/training/modules/custom-model-ai-vision-image-classification/3-create-custom-project)
14. [Containers. AI Services in Containers, in AKS, ACI, or even locally](https://learn.microsoft.com/en-us/training/modules/investigate-container-for-use-with-ai-services)
15. [Containers. Run services in Isolated Environment disconnected from the internet](https://learn.microsoft.com/en-us/azure/cognitive-services/containers/disconnected-containers)  
16. [Analyze Video Indexer. Widgets Integration and API](https://learn.microsoft.com/en-us/training/modules/analyze-video/4-use-video-indexer-widgets-apis)
17. [Semantic Ranking configuration in AI Search Index](https://learn.microsoft.com/en-us/training/modules/use-semantic-search/3-set-up-semantic-search)
18. [Knowledge Store & Knowledge Mining with AI Search](https://learn.microsoft.com/en-us/training/modules/create-knowledge-store-azure-cognitive-search/1-introduction)
19. [Integrate OpenAI into App. Useful Lab](https://learn.microsoft.com/en-us/training/modules/develop-applications-openai/3-integrate-app?pivots=csharp)
20. [Host Mistral and other models in AI Hub](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-mistral?tabs=mistral-large&pivots=programming-language-python)
21. [AI Language. Multi-turn multi-step conversation](https://learn.microsoft.com/en-us/training/modules/create-question-answer-solution-ai-language/5-implement-multi-turn-conversation)
22. [AI Language. Conversation Language understanding. Classical way to build AI-assistant. Utterances: Turn-on Turn-off & Smart home](https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/2-understand-resources-for-building)
23. [AI Language. Custom Named Entities Recognition. Laws, Business Cases](https://learn.microsoft.com/en-us/training/modules/custom-name-entity-recognition/2-understand-custom-named)  
24. [Key Phrases Extraction from text, Sentiment Analysis, Linked Entities](https://learn.microsoft.com/en-us/training/modules/analyze-text-ai-language/4-extract-key-phrases)
25. [Translate speech to text. Materials](https://learn.microsoft.com/en-us/training/modules/translate-speech-speech-service/4-synthesize-translation)    
26. [Translate speech to text and synthesize the output if needed. Example](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-translation?pivots=programming-language-csharp&tabs=macos%2Cterminal)
27. [AI Speech. Speech Synthesis](https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/6-speech-synthesis-markup)
28. [Run Cognitive Services in Docker](https://learn.microsoft.com/en-us/azure/ai-services/containers/disconnected-containers)
29. [Custom Vision. Deploy Custom Vision on the edge devices (phones) using compact models](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-your-model)
30. [Custom Vision. Recognize issues in factory. Upload images, Tag Images, and Train the Model](https://learn.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/quickstarts/image-classification?tabs=visual-studio&pivots=programming-language-csharp)  
31. [Anomaly Detector for IoT. Univariate Detector (multi-stream)](https://learn.microsoft.com/en-us/azure/cognitive-services/anomaly-detector/overview#univariate-anomaly-detection)  

### Azure Search & Document Intelligence
1. [Cognitive Search. Video](https://www.youtube.com/watch?v=5z32NS4IG0w)
2. [Cognitive Search. From Zero to Hero](https://www.youtube.com/watch?v=shT9-7AofKU&t=1s)
3. [Cognitive Search. Indexers. AI Enrichment. Build-in Skills](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/azure-ai-search.md)
4. [Document Intelligence](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Document-intelligence.md)

### Machine Learning Materials
1. [Machine Learning](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Machine-Learning.md)  
    a. [Machine Learning lab by Microsoft](https://microsoftlearning.github.io/mslearn-ai-fundamentals/Instructions/Labs/01-machine-learning.html)  
3. [How Deep Learning Works](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/Deep-Learning-Works.md)

## Extra materials
1. [Vector Database selection & comparison. VectorDB](https://superlinked.com/vector-db-comparison)  
2. [Transformer Explainer. Transformer Explainer is an interactive visualization tool designed to help anyone learn how Transformer-based models like GPT work](https://github.com/poloclub/transformer-explainer)
3. [Table extraction in RAG systems](https://ai.plainenglish.io/table-extraction-using-llms-unlocking-structured-data-from-documents-50cf21c98509)

## Practical Part. Table of Content
1. [Example:ConsoleApp CommandGuess](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/tree/main/ChatGPT)  
2. [Example: Azure Function with ChatGPT (completion and chat-completion)](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/tree/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction)  
3. [Example: Integration with PowerAutomate](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/PowerAutomate-Integration.md)  
4. [Example: Integration with PowerApp](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/PowerApp-Integration.md)  
5. Integration with Outlook (In progress)
6. [OpenAI + PowerAutomate Workshop by me.pptx](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/files/11840513/Workshop.Introduction.pptx)  
7. [Example: OpenAI + Redis](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/ChatGPT.AzureFunction/ChatGPTChatWithCache.cs)  
8. [BMW Dealer assistant. ChatGPT Chat + Startup + Redis + Context](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/tree/main/DealerAssistant)
9. [Get Embedding](https://github.com/Glareone/OpenAI-ChatGPT-best-practices/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/ChatGPT.AzureFunction/Embedding.cs)
10. [Form Recognizer Cognitive Service](https://github.com/Glareone/OpenAI-ChatGPT-best-practices/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/ChatGPT.AzureFunction/FormRecognizer.cs)
11. Content Filters (in progress)
12. [OpenAI straightforward examples](https://platform.openai.com/examples)
13. [Azure Bot Service & Chatbot Framework](https://github.com/Glareone/OpenAI-ChatGPT-best-practices/blob/main/Azure%20Bot%20Service.%20Usage/readme.md)
14. [LangChain meets Go](https://github.com/Glareone/OpenAI-ChatGPT-best-practices/blob/main/Langchain%20meets%20Go/readme.md)
15. TenzorZero Framework (In progress)
16. [Key Phrases Extraction. AI Language. Sentiment Analysis. Extracted Linked Entities](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/AI-Language.md)
17. [AI Search and Custom Skill using Azure Function](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/AI%20Search%20and%20Custom%20Skills)
18. Document Intelligence, Best Practices (In progress)
19. [MCP Server example using FastMCP](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/MCPServers/FastMCP-Example)

---
## Advanced Topics. Theory and Practice.
### 1. Advanced Evaluation Metrics & Methodologies
1. [Document Retrieval Metrics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md)  
    a. [NDCG@K (Normalized Discounted Cumulative Gain)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md) - Ranking quality with relevance grades  
    b. [Mean Reciprocal Rank (MRR)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md#mrr-mean-reciprocal-rank) - First relevant document positioning. How quickly users find their first relevant result. Critical for RAG user experience.  
    c. [Contextual Relevancy](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md#contextual-relevancy) - How relevant is the retrieved context to the user's question?  
    c. [Expected Reciprocal Rank (ERR)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md) - User behavior modeling with graded relevance  
    d. [Rank-Biased Precision (RBP)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document%20Retrieval%20Metrics.md) - Early result weighting strategies  
    e. [Embedding Quality Metrics](https://github.com/Glareone/AI-LLM-RAG-best-practices/edit/main/README.md) - Intra-cluster vs inter-cluster distance analysis. Quality of your vector space - are similar documents close together   
2. [Document Retrieval Metrics 2](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Document_Retrieval_Metrics_2.md)  
    a. Fidelity - Measures recall quality - what percentage of all relevant documents in your dataset were actually retrieved in the top-n results.  
    b. XDCG - Ranking quality within your retrieved top-k chunks, ignoring the rest of your document collection   
    c. XDCG vs NDCG  
    d. Max Relevance N - highest relevance score among your top-k retrieved chunks  
    e. Holes - Counts missing ground truth data  
3. [Response Quality Metrics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics.md)  
    a. [F1, Recall, Precision. Fundamental metrics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Fundamental%20Metrics%20F1%20Precision%20Recall.md)   
    b. [BLEU Score - N-gram overlap evaluation](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics.md)   
    c. [ROUGE (L/1/2) - Recall-oriented summarization metrics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics.md)  
    d. [G-Eval (LLM as a judge) - Sophisticated evaluation framework that uses LLMs themselves to evaluate outputs based on detailed criteria.](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics.md)  
    d. [BERTScore - Semantic similarity using contextualized embeddings](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics.md)  
    e. [BLEURT](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics%202.md#bleurt---bert-based-learned-evaluation-metric) - BERT-based learned evaluation metric  
    f. SacreBLEU - Standardized BLEU with proper tokenization  
    g. [METEOR](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Response%20Quality%20Metrics%202.md#meteor--synonym-and-paraphrase-consideration) - Synonym and paraphrase consideration  
    h. CIDEr - Consensus-based evaluation  
    i. CHRF - Character-level F-score for multilingual evaluation  
4. Human-Correlation Metrics   
    a.  Preference-Based Ranking - Win/loss ratios in A/B testing  
    b. Pearson/Spearman Correlation - Human judge alignment  
    c. Likert Scale Rating Systems - Multi-point evaluation frameworks

### 2. RAG Evaluation Frameworks and Libraties. Agentic Application Evaluation
1. [RAG System assessment and quality control:](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/RAG%20System%20assessment%20and%20quality%20control.md)  
    a. LangWatch  
    b. LangFuse    
    b. Galileo   
    c. Ragas  
    d. DeepEval  
    e. TrueLens  
    f. HuggingFace (NEW, in progress)    
    g. AI Foundry
2. [Agentic Application Evaluation](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/AI_agents/Agentic_Evaluations.md)  
    a. General Agentic Application Evaluations  
    b. Monitoring  
    c. Trajectory Evaluation  
    d. Structure of the Evaluation  
    e. Application Improvements using G-Eval (LLM-as-a-Judge)  

### 3. Advanced ML Architecture & Training
1. Neural Network Fundamentals   
    a. ReLU vs Advanced Activations (GELU, Swish/SiLU)
    b. Layer Normalization vs Batch Normalization - Training stability techniques  
    c. Gradient Clipping - Exploding gradient prevention  
    d. Mixed Precision Training - FP16/BF16 memory optimization  
2. CNN Advanced Concepts   
    a. Kernel Size Impact - Local vs global feature extraction (3x3 vs 7x7)  
    b. Parameter Sharing Benefits - Translation invariance principles  
    c. Hierarchical Feature Learning - Low-level to high-level progression  
    d. CNN vs MLP Scalability - O(k×c×f) vs O(n×m) parameter complexity  
3. Advanced Training Techniques  
    a. Learning Rate Scheduling - Cosine annealing, linear decay  
    b. Warmup Steps - Training stability (10% of total steps)  
    c. Checkpoint Averaging - Model stability improvement  
    d. Gradient Accumulation - Simulating larger batch sizes  

### 4. [Parameter-Efficient Fine-tuning (PEFT)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/Fine%20Tuning/Readme.md)
<img width="709" height="922" alt="image" src="https://github.com/user-attachments/assets/c5e5c8f7-1721-4684-96e6-534652e3c8e9" />

```txt
SFT = What you're doing (the training objective/paradigm)
  - Training on prompt-response pairs in a supervised manner
  - The goal is to teach the model to follow instructions or perform specific tasks

PeFT/LoRA = How you're doing it (the training technique/method)
  - A more efficient way to update model weights
  - Instead of updating all billions of parameters, you only update a small subset or add small adapter layers

PeFT is orthogonal to the training objective.

Training Objective (WHAT):        Implementation Method (HOW):
├─ Pretraining                   ├─ Full fine-tuning (update all params)
├─ Supervised Fine-Tuning (SFT)  └─ PeFT (LoRA, QLoRA, etc.)
├─ RLHF/Preference Tuning             └─ Only update small adapters
└─ Continued Pretraining

PeFT/Lora/QLora could be used in:
  * Stage 2 - Supervised Fine-Tuning. You can use PeFT/LoRA when doing supervised fine-tuning with prompt→hand-written answer pairs  
  * Stage 3 - Reinforcement Learning. RLHF/preference tuning. You can use PeFT/LoRA during RLHF when training with human preferences  
  * Stage 4 - Fine-tuning. Additional fine-tuning. This general fine-tuning step (creating the fine-tuned base LLM) could also use PeFT/LoRA  .
  * Stage 1` - Even continued pretraining.
```

1. [LoRA (Low-Rank Adaptation)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/Fine%20Tuning/LoRa.md)  
    a. [Rank Parameter (r) - 8-64 range, efficiency vs capacity trade-off](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Fine%20Tuning/Readme.md#a-rank-parameter-r---8-64-range-efficiency-vs-capacity-trade-off)  
    b. [Alpha Scaling Factor - Typically 16-32](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Fine%20Tuning/Readme.md#b-alpha-scaling-factor---typically-16-32)  
    c. [Target Module Selection - Query, value, key, output projections](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Fine%20Tuning/Readme.md#c-target-module-selection---query-value-key-output-projections)    
    d. [AdaLoRA - Adaptive rank allocation](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Fine%20Tuning/Readme.md#d-adalora---adaptive-rank-allocation)  
    e. [QLoRA - 4-bit quantized LoRA for memory efficiency](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Fine%20Tuning/Readme.md#d-adalora---adaptive-rank-allocation)  
2. [Training Parameters](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/Fine%20Tuning/Training%20Parameters.md)  
    a. Learning Rate Ranges - 1e-5 to 5e-4 for LLMs with warmup  
    b. Batch Size Optimization - 8-32 full fine-tuning, 64-128 LoRA  
    c. Sequence Length Limits - 512-4096 tokens task dependency  
    d. Weight Decay (L2 Regularization) - λ||w||² with λ = 1e-4 to 1e-2  

### 5. Advanced Retrieval & Re-ranking
1. [Re-ranking Algorithms](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Advanced%20Retrieval%20&%20Re-ranking.md)   
    a. Reciprocal Rank Fusion (RRF) - RRF_score = Σ(1/(k + rank_i))  
    b. Cross-encoder vs Bi-encoder - Accuracy vs speed trade-offs  
    c. Neural Re-rankers - BERT/T5-based cross-attention models  
    d. Learning to Rank (LTR) - ML-based ranking optimization  
    e. Score Normalization Techniques - Min-max, z-score, sigmoid   

2. [Advanced Retrieval Concepts](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Advanced%20Retrieval%20&%20Re-ranking.md)  
    a. Semantic Similarity Scoring - Cosine similarity between embeddings  
    b. Context Preservation - Chunk coherence maintenance  
    c. Window Size Optimization - Re-ranking candidate selection (100-1000)  

### 6. MLOps & Production Platforms
1. Evaluation Platforms  
    a. AI Foundry (Microsoft) - Model testing and evaluation  
    b. Weights & Biases (W&B) - Experiment tracking  
    c. Neptune.ai - MLOps platform capabilities  
    d. LangSmith (LangChain) - LLM application testing  
    e. [Phoenix (Arize AI) - LLM observability and evaluation](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/tree/main/Arize-Phoenix)  
      - [trajectory analysis](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L9.ipynb)  
      - [phoenix. evaluations](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L7_add_evaluations_to_phoenix.ipynb)  
      - [tool and span tracing](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L5_with_arize_phoenix.ipynb)  

3. Model Management  
    a. MLFlow - Model lifecycle management  
    b. DVC (Data Version Control) - Data and model versioning  
    c. BentoML - Model serving framework architecture  

### 7. Advanced LLM Frameworks. LangChain. LangGraph. Semantic Kernel.  
![image](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/assets/4239376/f9ed16f2-80ba-42c9-b6fc-50b488cee8d2)  
![image](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/assets/4239376/86d0f7e2-cf7f-4a2c-93a1-a97427498ed0)  
1. [LangChain. Demo examples wiht pipelines](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/Langchain/first-experiment)  
    a. LangChain using Golang (In Progress)  
2. [LangGraph Basics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md)  
    a. [When to Use What (Decision Framework)](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md#0%EF%B8%8F%E2%83%A3-when-to-use-what-decision-framework)  
    b. [Core LangGraph Primitives: StateGraph & MessageGraph, Compilation model, Checkpointers, Thread/Run concepts](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md#0%EF%B8%8F%E2%83%A3-when-to-use-what-decision-framework)   
    c. [Graph Execution Model: how LangGraph executes iteratively. StateGraph & MessageGraph](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md#0%EF%B8%8F%E2%83%A3-when-to-use-what-decision-framework)  
    d. [LangGraph Checkpointers: MemorySaver, SqliteSaver, PostgresSaver](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md#0%EF%B8%8F%E2%83%A3-when-to-use-what-decision-framework)  
    e. [LangGraph composition: START, END, Conditional Edge. Parallel node execution. Cycle limit (recursion_limit), infinite loops](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Basics.md#2%EF%B8%8F%E2%83%A3-graph-execution-model-start--end-nodes-conditional-nodes)  
    e. Subgraphs & Composition: when to use subgraphs vs separate graphs  
    f. Error Handling & Interrupts (Critical for production)
3. [LangGraph. Patterns. Examples](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/LangGraph)  
    a. [React. Using LangGraph. In Progress](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/LangGraph/Examples/ReACT/ReACT-Lab2-LangGraph)  
    b. [React. Simple LangGraph Prototype](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/LangGraph/LangGraph_Prototype)
    c. [ReACT. Pre-coded loop + LLM to calculate the total weight of dogs](https://github.com/Glareone/AI-LLM-RAG-best-practices/tree/main/LangGraph/Examples/ReACT/ReACT_Lesson_1)  
4. [LangGraph Advanced Topics](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/LangGraph_Advanced.md)  
    a. State Management - Persistent conversation state  
    b. Graph Architecture - Nodes and edges for complex workflows  
    c. Conditional Routing - Dynamic flow based on LLM decisions  
    d. Human-in-the-Loop - Approval gates and manual interventions  
    e. Parallel Processing - Concurrent graph branch execution  
5. [LangGraph Examples and Prototypes](https://github.com/Glareone/AI-LLM-RAG-best-practices/edit/main/README.md)  
6. LangGraph System Prompt Techniques  
    a. [Decision-Tree Prompts & Pattern](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangGraph/Prompt-Decision-Tree.md)   
    b. [Multi-Agent Prompt & Pattern. Primitive Version](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangGraph/Prompt-Multi-Agent.md)   
    c. [Plan-Execute Prompt & Pattern](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangGraph/Prompt-Plan-Execute.md)  
    d. [ReAct. Prompts & Ideas](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangGraph/Prompt-ReACT.md)  
    e. [Prompt-Reflection Pattern. Idea](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangGraph/Prompt-Reflection.md)  
7. Semantic Kernel (Microsoft)  
    a. Kernel Architecture - Central orchestration engine  
    b. Plugin System - Reusable functions (native C# or prompt-based)  
    c. Planners - Automatic workflow generation  
    d. Memory Management - Vector-based semantic memory patterns
8. Magentic One + Semantic Kernel
9. Advanced Framework Concepts  
    a. Multi-Agent Systems - Collaborative AI agent coordination  
    b. Error Recovery Strategies - Retry logic, fallback mechanisms  
    c. Async Execution - Resource management at scale

### 8. Structured Output & Schema Design
1. Pydantic Advanced Usage  
    a. Field Validation - Custom validators, constraints (min/max, regex)  
    b. JSON Schema Generation - Automatic API documentation  
    c. Error Handling - Detailed validation error message design  
    d. Schema Compliance Monitoring - Production tracking metrics  
2. Best Practices  
    a. Schema Complexity vs Success Rates - Optimization strategies  
    b. Retry Logic Implementation - Parse failure handling  
    c. Validation Feedback Loops - Error correction workflows  

### 9. Massive Parallel Training (Enterprise Scale)  
1. Distributed Training Strategies  
    a. Data Parallelism - Batch distribution across GPUs  
    b. Model Parallelism - Layer splitting across devices  
    c. Pipeline Parallelism - Sequential processing stages  
    d. Gradient Synchronization - AllReduce, parameter servers  
    e. Mixed Precision Training - Memory efficiency optimization  

### 10. Advanced Overfitting Prevention  
1. Regularization Techniques  
    a. Early Stopping - Validation loss plateau detection  
    b. Dropout Rates - 0.1-0.3 optimal ranges  
    c. Training/Validation Loss Curves - Overfitting gap analysis  
    d. Cross-validation Strategies - 5-10 fold robust evaluation

### 11. GenAI Design Patterns
1. Logits Masking
2. Grammar
3. Style Transfer
4. Reverse Neutralization
5. Content Optimization

### [12. Homomorphic encryption (encryption on the fly) in LLMs](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Homomorphic_Encryption_Main.md)
1. [Main Topics. What, Why, How](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Homomorphic_Encryption_Main.md)
2. [Q&A. Quick references](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Q&A_Quick_References.md#qa-quick-references)    
    a. [Whether or not. Use Cases](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Q&A_Quick_References.md#qa-quick-references)  
    b. [How to Start](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Q&A_Quick_References.md#qa-quick-references)  
    c. [Parameters](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Q&A_Quick_References.md#qa-quick-references)  
    d. [Performance and Trade-offs](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Q&A_Quick_References.md#qa-quick-references)    
2. Examples  
    a. [TenSeal, Concrete-ML, Microsoft Seal](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/advanced-topics/Homomorphic/Homomorphic_Examples.md)  
---

### AI System monitoring, evaluation and tracking. LangWatch vs LangFuse vs Phoenix vs AI Foundry
1. [LangWatch vs LangFuse vs AI Foundry comparison](https://github.com/Glareone/AI-LLM-RAG-best-practices/blob/main/LangWatch/LangWatch%20And%20LangFuse.md)
2. [Examples. Arize Phoenix for Python](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/tree/main/Arize-Phoenix)
  a. [Phoenix. Trajectory analysis](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L9.ipynb)  
  b. [Phoenix. Evaluations](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L7_add_evaluations_to_phoenix.ipynb)  
  c. [Phoenix. Tool and Span tracing](https://github.com/Glareone/AI-RAG-Basics-To-Advanced-With-Examples/blob/main/Arize-Phoenix/L5_with_arize_phoenix.ipynb)  
4. Examples. Arize Phoenix for LangGraph (In progress)  
---

### Advanced Topics. Practice. Semantic Kernel Knowledge base
1. [Semantic kernel and AI Assistant](https://devblogs.microsoft.com/semantic-kernel/assistants-a-first-look-into-using-openai-assistants-with-semantic-kernel/)
2. [Creative Writing Assistant with Semantic Kernel and .Net Aspire](https://devblogs.microsoft.com/semantic-kernel/guest-blog-creative-writing-assistant-a-multi-agent-app-sample-with-semantic-kernel-net-aspire/?ocid=semantic-kernel_eml_tnp_autoid150_title)

### Advanced Topics. Practice. SemanticKernel.
1. [Initial Example](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/SemanticKernel.ConsoleApp/ShortIntentExtraction.cs)
2. [Interactive Chat with Chat History](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/SemanticKernel.ConsoleApp/InteractiveChatFunction.cs)
3. [Model Switching. Hugging Face](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/SemanticKernel.ConsoleApp/ModelSwitching_HuggingFaceModel.cs)
4. [Semantic Function for Conversational Chat](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/SemanticKernel.ConsoleApp/SemanticFunctionForConversationalChat.cs)
5. [Semantic Kernel Pipeline](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/blob/main/ChatGPT.AzureFunction/ChatGPT.AzureFunction/SemanticKernel.ConsoleApp/SemanticKernelPipeline.cs)

---
### RAG. Cheatsheet for .Net
---
![image](https://github.com/Glareone/OpenAI-and-ChatGPT-meet-.Net/assets/4239376/2b8ca392-dc0e-4ebc-9f85-5bcbb8bf27bb)


