{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d40cab-6377-4609-a1c0-56ae790db763",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lab 2: Tracing your Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3410aa-5a1e-49d4-b42c-94a483503b5f",
   "metadata": {},
   "source": [
    "In this lab, you will collect traces from your agent code:\n",
    "- for OpenAI LLM calls, you will use OpenAIInstrumentor which automatically collects spans of type LLM containing the input and output of an LLM call;\n",
    "- for any other steps of your agent you want to track, you will manually instrument them by creating corresponding spans.\n",
    "\n",
    "When creating spans, you need to choose the [span kind](https://docs.arize.com/arize/llm-tracing/tracing/what-are-traces#span-kind). For this agent, you will create spans of types: \n",
    "- chain: to represent the starting point of a chain of steps or a link between different steps;\n",
    "- tool: to represent the call to an external tool;\n",
    "- agent: to represent the main span that encompasses calls to LLMs and Tools.\n",
    "\n",
    "Here's an example of how the spans might look like when you run the agent to respond to a user's query.\n",
    "<img src=\"images/spans_agent.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de494e9a-2003-4ee5-8184-eae1ab603fff",
   "metadata": {},
   "source": [
    "You will create a span of type `agent` to represent the main span (response of an agent to a user's query). Within this span, you will create a span of a type `chain` to represent a single router call, and to indicate that there will be a series of steps taken under this router call. This includes the main llm call made by the router which will be automatically collected, and a span to of type `chain` to represent how the tools were handled. Under this chain, you wil create a span of type `tool` for each tool executed and under each tool, there might an llm call and maybe another chain of steps.\n",
    "\n",
    "This notebook contains the same code of the previous lab but with additional code that allows collecting traces from your code. Try to watch first the video to understand how the code is instrumented and then run all cells and at the end (**last code cell**), check out the **link to Phoenix UI** to examine the spans collected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730a734-601c-415e-8004-4d8846e769dc",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "id": "6a8c367b-c83a-42d1-9431-223da62d033e",
   "metadata": {
    "height": 200,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.330402Z",
     "start_time": "2025-12-07T14:39:48.327537Z"
    }
   },
   "source": [
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from helper import get_azure_openai_configurations, get_phoenix_endpoint"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "44c0c8b5-256e-4c8e-ac10-90a17e068c47",
   "metadata": {
    "height": 132,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.344055Z",
     "start_time": "2025-12-07T14:39:48.341931Z"
    }
   },
   "source": [
    "import phoenix as px\n",
    "from phoenix.session.session import launch_app\n",
    "\n",
    "import os\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "384dafee-d367-4d39-98c4-8ad711845cbe",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f6792c7-5246-4aeb-a683-9f8ac5b921a1",
   "metadata": {
    "height": 98,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.362730Z",
     "start_time": "2025-12-07T14:39:48.347828Z"
    }
   },
   "source": [
    "# initialize the OpenAI client\n",
    "openai_api_config = get_azure_openai_configurations()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=openai_api_config.api_version,\n",
    "    azure_endpoint=openai_api_config.azure_endpoint,\n",
    "    api_key=openai_api_config.api_key,\n",
    ")\n",
    "\n",
    "MODEL = openai_api_config.deployment"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "ad06b543-93eb-4b4f-8ba8-59067cf000ed",
   "metadata": {},
   "source": [
    "# Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91f275-e864-4be0-83d5-591c7ba2a9ce",
   "metadata": {},
   "source": [
    "Phoenix is an AI observability platform that you can use to visualize the traces collected from your code. The Phoenix server is already launched for you, and you are provided with its endpoint (address) so you can configure a TracerProvider to send traces to Phoenix.\n",
    "\n",
    "**Note**: You can launch a local version of Phoenix in your own local notebook environment using `session = px.launch_app()` (as shown [here](https://docs.arize.com/phoenix/deployment/environments#notebooks)). In this notebook, you don't need to launch the Phoenix server, it's already configured for you."
   ]
  },
  {
   "cell_type": "code",
   "id": "c5401d4e-d784-4295-a28c-f632a2b642ad",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.366638Z",
     "start_time": "2025-12-07T14:39:48.365419Z"
    }
   },
   "source": [
    "PROJECT_NAME = \"tracing-agent\""
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.628434Z",
     "start_time": "2025-12-07T14:39:48.368927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To start phoenix in a notebook environment, run:\n",
    "# This will start a local Phoenix server. You can initialize the phoenix server with various kinds of data (traces, inferences).\n",
    "\n",
    "# 12.x phoenix version runs this way\n",
    "session = launch_app()\n",
    "\n",
    "\n",
    "# By default, Phoenix does not persist your data when run in a notebook.\n",
    "\n",
    "# If you want to start a phoenix server to collect traces, you can also run phoenix directly from the command line:\n",
    "# This will start the phoenix server on port 6006. If you are running your instrumented notebook or application on the same machine, traces should\n",
    "# automatically be exported to http://127.0.0.1:6006 so no additional configuration is needed. However if the server is running remotely, you will\n",
    "# have to modify the environment variable PHOENIX_COLLECTOR_ENDPOINT to point to that machine (e.g. http://<my-remote-machine>:<port>)\n",
    "# >>> phoenix serve\n",
    "\n",
    "\n"
   ],
   "id": "5f5d1c0a298a6e88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "347486ef-8394-4fa9-88f0-cf4bcf3d6078",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.634461Z",
     "start_time": "2025-12-07T14:39:48.631006Z"
    }
   },
   "source": [
    "\n",
    "tracer_provider = register(\n",
    "    project_name=PROJECT_NAME,\n",
    "    endpoint= get_phoenix_endpoint() + \"v1/traces\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”­ OpenTelemetry Tracing Details ðŸ”­\n",
      "|  Phoenix Project: tracing-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://127.0.0.1:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  âš ï¸ WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "6cd5a765",
   "metadata": {},
   "source": [
    "**Note**: To check Phoenix UI, you can open the link provided in the last code cell. The link shown in the output of the previous cell includes this additional string \"v1/traces\" and represents where the traces will be collected not the UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b2024-1b99-45bf-97c0-5634fa59471f",
   "metadata": {},
   "source": [
    "Setup the OpenAIInsrumentor to automatically collect OpenAI LLM calls from your code."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd684301-6e67-42c0-a247-4abf443f399a",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.640865Z",
     "start_time": "2025-12-07T14:39:48.639134Z"
    }
   },
   "source": [
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "id": "c3e55495-6fa6-4982-98f5-72247caf905c",
   "metadata": {},
   "source": [
    "Get the tracer (object that creates spans) from the tracer provider (object that provides/sends the collected traces to Phoenix). You will use the tracer object to create the chain, tool and agent spans."
   ]
  },
  {
   "cell_type": "code",
   "id": "53b81feb-dcc2-434a-939d-64f1cb3dc83c",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.647195Z",
     "start_time": "2025-12-07T14:39:48.645924Z"
    }
   },
   "source": [
    "tracer = tracer_provider.get_tracer(__name__)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "8b976279-fcb8-433d-a7e9-4b61e8e4a631",
   "metadata": {},
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f98a21-d25c-4334-8604-2ab8c9d0e2af",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "code",
   "id": "16729638-bcbf-41d6-ad19-b03df8c6d437",
   "metadata": {
    "height": 47,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.652297Z",
     "start_time": "2025-12-07T14:39:48.651058Z"
    }
   },
   "source": [
    "# define the path to the transactional data\n",
    "TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "905be4f0-3be4-4832-ac63-8d46c7385935",
   "metadata": {
    "height": 149,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.655534Z",
     "start_time": "2025-12-07T14:39:48.654210Z"
    }
   },
   "source": "# prompt template for step 2 of tool 1\nSQL_GENERATION_PROMPT = \"\"\"\nGenerate a DuckDB SQL query based on a prompt. Do not reply with anything besides the SQL query.\nThe prompt is: {prompt}\n\nThe available columns are: {columns}\nThe table name is: {table_name}\n\nIMPORTANT DATA TYPE INFORMATION:\n- The 'date' column is stored as VARCHAR (string) in format 'YYYY-MM-DD', NOT as a DATE type\n- Do NOT use YEAR(), MONTH(), or other date functions directly on the 'date' column\n- For year filtering, use: WHERE date BETWEEN 'YYYY-01-01' AND 'YYYY-12-31'\n- For month filtering, use: WHERE date BETWEEN 'YYYY-MM-01' AND 'YYYY-MM-31'\n- Or use string comparison: WHERE date >= '2021-01-01' AND date <= '2021-12-31'\n- If you need to extract year/month, use: CAST(date AS DATE) first, then apply date functions\n\nExample correct queries:\n- Get 2021 data: WHERE date BETWEEN '2021-01-01' AND '2021-12-31'\n- Get November 2021: WHERE date BETWEEN '2021-11-01' AND '2021-11-30'\n- Extract year: strftime('%Y', CAST(date AS DATE)) or YEAR(CAST(date AS DATE))\n\"\"\"",
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "f3282aac-c4ca-4798-890b-53bf347b9e51",
   "metadata": {
    "height": 234,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.658921Z",
     "start_time": "2025-12-07T14:39:48.657482Z"
    }
   },
   "source": [
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "5bc361a6-1251-454b-bd22-819c5274ba77",
   "metadata": {
    "height": 557,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.662568Z",
     "start_time": "2025-12-07T14:39:48.660721Z"
    }
   },
   "source": [
    "# code for tool 1\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"sales\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        # this \"with tracer.start_as_current_span\" represents the logging of the execution of the SQL query\n",
    "        # used together with @tracer.tool() decorator\n",
    "        # usually it's useful when you want to understand what went wrong in a tool execution\n",
    "        # for instance, sql query was generated correctly but execution failed\n",
    "        with tracer.start_as_current_span(\n",
    "            \"execute_sql_query\", \n",
    "            openinference_span_kind=\"chain\"\n",
    "        ) as span:\n",
    "            span.set_input(sql_query)\n",
    "            # step 3: execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "f3493199-ffcc-4027-8599-64638db0237f",
   "metadata": {},
   "source": [
    "### Tool 2: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb9e108e-bf44-4c90-a5ee-af4a4597a77c",
   "metadata": {
    "height": 98,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.665650Z",
     "start_time": "2025-12-07T14:39:48.664520Z"
    }
   },
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "b6f25872-1d6f-492a-9fbc-0f153d78e0a2",
   "metadata": {
    "height": 234,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.668835Z",
     "start_time": "2025-12-07T14:39:48.667423Z"
    }
   },
   "source": [
    "# code for tool 2\n",
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "id": "0f14a090-d5c9-4a3f-b92f-65932e143c91",
   "metadata": {},
   "source": [
    "### Tool 3: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3691330-7300-46e0-8ff3-1d7712d4c292",
   "metadata": {
    "height": 98,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.671669Z",
     "start_time": "2025-12-07T14:39:48.670584Z"
    }
   },
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "b2a551ae-35e5-460e-9ae0-cd1e5c7f6550",
   "metadata": {
    "height": 115,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.675021Z",
     "start_time": "2025-12-07T14:39:48.673380Z"
    }
   },
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "7e99edc6-a59e-4ef5-a05a-55501c2a4f54",
   "metadata": {
    "height": 710,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.678651Z",
     "start_time": "2025-12-07T14:39:48.676929Z"
    }
   },
   "source": [
    "# code for step 1 of tool 3\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data, \n",
    "                                                         visualization_goal=visualization_goal)\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "e99b0e1f-642e-429e-89c7-371d7045dda7",
   "metadata": {
    "height": 98,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.681544Z",
     "start_time": "2025-12-07T14:39:48.680419Z"
    }
   },
   "source": [
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "ce93df0f-fd43-4145-a829-78d53c6de2cf",
   "metadata": {
    "height": 285,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.684679Z",
     "start_time": "2025-12-07T14:39:48.683240Z"
    }
   },
   "source": [
    "# code for step 2 of tool 3\n",
    "@tracer.chain()\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "a907f1b0-e6d2-4649-9282-0cf8e48f5ffd",
   "metadata": {
    "height": 132,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.687603Z",
     "start_time": "2025-12-07T14:39:48.686341Z"
    }
   },
   "source": [
    "# code for tool 3\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "id": "9b2f2911-986f-4490-a9a0-9ce4c9943a6e",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0d59f93-5af3-4ff3-aa0f-3e0d2162fd5e",
   "metadata": {
    "height": 931,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.691074Z",
     "start_time": "2025-12-07T14:39:48.689257Z"
    }
   },
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\", \n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "id": "d29a427c-3cdf-4921-9fc3-9056d5fa5e26",
   "metadata": {},
   "source": [
    "## Router Logic"
   ]
  },
  {
   "cell_type": "code",
   "id": "62a94771-21cb-4fe9-a76f-8a90b843f866",
   "metadata": {
    "height": 234,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.694060Z",
     "start_time": "2025-12-07T14:39:48.692719Z"
    }
   },
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \n",
    "                         \"content\": result, \n",
    "                         \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "6d2288f8-0b3d-4719-b5c7-155a78c059ce",
   "metadata": {
    "height": 64,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.696842Z",
     "start_time": "2025-12-07T14:39:48.695782Z"
    }
   },
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "9a5e2f71-c008-45c3-955e-2abebfabb8a6",
   "metadata": {
    "height": 625,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.700635Z",
     "start_time": "2025-12-07T14:39:48.698617Z"
    }
   },
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        # Router Span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\", openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "    \n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "41f43a1c-b6bf-45d8-9fb5-f677a0db350e",
   "metadata": {
    "height": 217,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:48.703858Z",
     "start_time": "2025-12-07T14:39:48.702490Z"
    }
   },
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"AgentRun\", openinference_span_kind=\"agent\"\n",
    "    ) as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "dcc6d06c-34b2-46af-b97f-506db6b01204",
   "metadata": {
    "height": 47,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:52.042768Z",
     "start_time": "2025-12-07T14:39:48.706233Z"
    }
   },
   "source": [
    "result = start_main_span([{\"role\": \"user\", \n",
    "                           \"content\": \"Which stores did the best in 2021?\"}])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: In 2021, the stores that performed the best in terms of total sales were:\n",
      "\n",
      "1. Store 1325 with total sales of 916,910.45\n",
      "2. Store 1328 with total sales of 915,993.75\n",
      "3. Store 1323 with total sales of 897,773.77\n",
      "4. Store 1321 with total sales of 890,050.52\n",
      "5. Store 1322 with total sales of 889,298.62\n",
      "\n",
      "These stores had the highest total sales figures for the year 2021. If you need more information or details about other stores, feel free to ask.\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "id": "d6eca7a9-f519-4a66-939e-7ca7ef2e09b9",
   "metadata": {},
   "source": [
    "## Link to Phoenix UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b3ea65-ba44-4ad3-a096-1d89cf55f374",
   "metadata": {},
   "source": [
    "After you run all code cells, you can open this link to check out the Phoenix UI and observe the collected spans.\n",
    "\n",
    "**Note**:  Make sure that the notebook's kernel is running when checking the Phoenix UI. If the link does not open, it might be because the notebook has been open or inactive for a long time. In that case, make sure to refresh the browser, run all cells and then check this link. The link provided in this notebook is different from the one shown in the video."
   ]
  },
  {
   "cell_type": "code",
   "id": "c65d57e3-9f20-49f6-b4bf-2e71141d5fb8",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-12-07T14:39:52.047457Z",
     "start_time": "2025-12-07T14:39:52.045768Z"
    }
   },
   "source": [
    "print(get_phoenix_endpoint())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:6006/\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"background-color:#grey; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ],
   "id": "bfdea0abea6e3cda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
